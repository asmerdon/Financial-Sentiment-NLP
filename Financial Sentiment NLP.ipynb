{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd506c2c-95d1-43e5-a62e-1415ca150b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'validation'])\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (from Hugging Face)\n",
    "dataset = load_dataset('zeroshot/twitter-financial-news-sentiment')\n",
    "# List the available splits\n",
    "print(dataset.keys())\n",
    "\n",
    "# Access the training and validation splits\n",
    "train_dataset = dataset['train']\n",
    "validation_dataset = dataset['validation']\n",
    "\n",
    "# Convert the training dataset to a DataFrame\n",
    "df_train = pd.DataFrame(train_dataset)\n",
    "df_validation = pd.DataFrame(validation_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31ab4c8e-f8e3-4285-80d7-c9c47f6e7c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  $BYND - JPMorgan reels in expectations on Beyo...      0\n",
      "1  $CCL $RCL - Nomura points to bookings weakness...      0\n",
      "2  $CX - Cemex cut at Credit Suisse, J.P. Morgan ...      0\n",
      "3  $ESS: BTIG Research cuts to Neutral https://t....      0\n",
      "4  $FNKO - Funko slides after Piper Jaffray PT cu...      0\n",
      "Index(['text', 'label'], dtype='object')\n",
      "label\n",
      "2    6178\n",
      "1    1923\n",
      "0    1442\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head())\n",
    "print(df_train.columns)\n",
    "print(df_train['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bd95aff-d2a3-4ce0-afdb-31634b62fa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove URLs, mentions, hashtags\n",
    "    text = re.sub(r'http\\S+|@\\S+|#\\S+', '', text)\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove stopwords\n",
    "    text_tokens = text.split()\n",
    "    filtered_text = ' '.join([word for word in text_tokens if word not in stop_words])\n",
    "    return filtered_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "439b722f-9d2c-4637-b22b-b948695debfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         bynd jpmorgan reels expectations beyond meat\n",
      "1    ccl rcl nomura points bookings weakness carniv...\n",
      "2    cx cemex cut credit suisse jp morgan weak buil...\n",
      "3                       ess btig research cuts neutral\n",
      "4               fnko funko slides piper jaffray pt cut\n",
      "Name: clean_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to the training data\n",
    "df_train['clean_text'] = df_train['text'].apply(preprocess_text)\n",
    "df_validation['clean_text'] = df_validation['text'].apply(preprocess_text)\n",
    "\n",
    "print(df_train['clean_text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d78a4d42-53cc-4c89-b5ea-1d9e99c259ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "# Fit the vectorizer on the training data\n",
    "X_train_tfidf = vectorizer.fit_transform(df_train['clean_text'])\n",
    "\n",
    "# Transform the validation data\n",
    "X_validation_tfidf = vectorizer.transform(df_validation['clean_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b8abca6-7c9c-4660-8e8f-1d8a33c4d15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(df_train['label'])\n",
    "y_validation = label_encoder.transform(df_validation['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23d7e5d8-d1e8-4b38-bacf-e51fff7d9ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(class_weight=&#x27;balanced&#x27;, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(class_weight=&#x27;balanced&#x27;, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(class_weight='balanced', kernel='linear')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#Support Vector Machine (linear, one against all method of classification)\n",
    "svm_classifier = SVC(kernel='linear', class_weight='balanced') #'balanced weights samples to for more accurate training\n",
    "svm_classifier.fit(X_train_tfidf, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a43bd2e2-569b-40c7-8093-f437f35f48bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7948073701842546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.69      0.62       347\n",
      "           1       0.69      0.72      0.71       475\n",
      "           2       0.90      0.84      0.87      1566\n",
      "\n",
      "    accuracy                           0.79      2388\n",
      "   macro avg       0.72      0.75      0.73      2388\n",
      "weighted avg       0.81      0.79      0.80      2388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicting\n",
    "y_pred = svm_classifier.predict(X_validation_tfidf)\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Use numerical labels as strings\n",
    "target_names = [str(label) for label in sorted(set(y_validation))]\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_validation, y_pred))\n",
    "print(classification_report(y_validation, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0e9c88e-fd69-4259-ab97-0b37a7e5dd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results:\n",
      "accuracy: 0.785 (+/- 0.006)\n",
      "precision_macro: 0.707 (+/- 0.005)\n",
      "recall_macro: 0.730 (+/- 0.002)\n",
      "f1_macro: 0.717 (+/- 0.003)\n",
      "Classification report on validation set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.71      0.64       347\n",
      "    positive       0.68      0.74      0.71       475\n",
      "     neutral       0.91      0.84      0.88      1566\n",
      "\n",
      "    accuracy                           0.80      2388\n",
      "   macro avg       0.73      0.76      0.74      2388\n",
      "weighted avg       0.82      0.80      0.81      2388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CROSS VALIDATION \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Prepare data\n",
    "X = df_train['text']  # Feature data: raw text from training set\n",
    "y = df_train['label']  # Labels: sentiment classes\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),  # Step 1: Convert text to TF-IDF features\n",
    "    ('svm', SVC(kernel='linear', class_weight='balanced'))  # Step 2: Train a linear SVM classifier\n",
    "])\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # Stratified 5-fold cross-validation\n",
    "\n",
    "# Cross-validation with detailed metrics\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']  # Evaluation metrics\n",
    "cv_results = cross_validate(pipeline, X, y, cv=cv, scoring=scoring)  # Perform cross-validation\n",
    "\n",
    "print(\"Cross-validation results:\")\n",
    "for metric in scoring:\n",
    "    scores = cv_results['test_' + metric]\n",
    "    print(f\"{metric}: {scores.mean():.3f} (+/- {scores.std():.3f})\")  # Print mean and std for each metric\n",
    "\n",
    "# Fit the pipeline on the entire training data\n",
    "pipeline.fit(X, y)  # Train the pipeline on the full training set\n",
    "\n",
    "# Prepare validation data\n",
    "X_validation = df_validation['text']  # Feature data: raw text from validation set\n",
    "y_validation = df_validation['label']  # Labels: sentiment classes from validation set\n",
    "\n",
    "# Predict on validation data\n",
    "y_pred = pipeline.predict(X_validation)  # Predict labels for validation data\n",
    "\n",
    "# Classification report on validation set\n",
    "print(\"Classification report on validation set:\")\n",
    "print(classification_report(y_validation, y_pred, target_names=['negative', 'positive', 'neutral']))  # Print detailed classification metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
